<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Advancing Perspectivist Ground Truthing with Social Science – Thesis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Thesis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Introduction</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-data-work-is-design-work" id="toc-the-data-work-is-design-work" class="nav-link" data-scroll-target="#the-data-work-is-design-work">The Data Work is Design Work</a>
  <ul class="collapse">
  <li><a href="#present-work" id="toc-present-work" class="nav-link" data-scroll-target="#present-work">Present Work</a></li>
  </ul></li>
  <li><a href="#mlai-relies-on-reference-data-from-human-annotations" id="toc-mlai-relies-on-reference-data-from-human-annotations" class="nav-link" data-scroll-target="#mlai-relies-on-reference-data-from-human-annotations">ML/AI relies on reference data from human annotations</a>
  <ul class="collapse">
  <li><a href="#issues-using-human-annotations-in-ml" id="toc-issues-using-human-annotations-in-ml" class="nav-link" data-scroll-target="#issues-using-human-annotations-in-ml">Issues using human annotations in ML</a>
  <ul class="collapse">
  <li><a href="#ml-treats-all-annotation-variance-as-noise-rather-than-signal" id="toc-ml-treats-all-annotation-variance-as-noise-rather-than-signal" class="nav-link" data-scroll-target="#ml-treats-all-annotation-variance-as-noise-rather-than-signal">ML treats all annotation variance as noise rather than signal</a></li>
  <li><a href="#human-annotations-arent-always-accurate" id="toc-human-annotations-arent-always-accurate" class="nav-link" data-scroll-target="#human-annotations-arent-always-accurate">Human annotations aren’t always accurate</a></li>
  <li><a href="#inadequate-reporting" id="toc-inadequate-reporting" class="nav-link" data-scroll-target="#inadequate-reporting">Inadequate reporting</a></li>
  <li><a href="#sampling-and-measurement-biases" id="toc-sampling-and-measurement-biases" class="nav-link" data-scroll-target="#sampling-and-measurement-biases">sampling and measurement biases</a></li>
  <li><a href="#ml-doesnt-treat-annotation-generating-process-as-an-instrument" id="toc-ml-doesnt-treat-annotation-generating-process-as-an-instrument" class="nav-link" data-scroll-target="#ml-doesnt-treat-annotation-generating-process-as-an-instrument">ML doesn’t treat annotation generating process as an instrument</a></li>
  <li><a href="#ml-ignores-perspectives-of-annotators" id="toc-ml-ignores-perspectives-of-annotators" class="nav-link" data-scroll-target="#ml-ignores-perspectives-of-annotators">ML ignores perspectives of annotators</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#tools-from-social-science-can-help" id="toc-tools-from-social-science-can-help" class="nav-link" data-scroll-target="#tools-from-social-science-can-help">Tools from Social Science can help</a>
  <ul class="collapse">
  <li><a href="#social-and-computational-sciences-have-different-focci" id="toc-social-and-computational-sciences-have-different-focci" class="nav-link" data-scroll-target="#social-and-computational-sciences-have-different-focci">Social and computational sciences have different focci</a></li>
  <li><a href="#issues-with-sampling" id="toc-issues-with-sampling" class="nav-link" data-scroll-target="#issues-with-sampling">Issues with sampling</a></li>
  <li><a href="#issues-with-instruments" id="toc-issues-with-instruments" class="nav-link" data-scroll-target="#issues-with-instruments">Issues with instruments</a></li>
  <li><a href="#a-tale-of-two-studies-the-case-of-personnel-selection" id="toc-a-tale-of-two-studies-the-case-of-personnel-selection" class="nav-link" data-scroll-target="#a-tale-of-two-studies-the-case-of-personnel-selection">A tale of two studies: the case of personnel selection</a></li>
  </ul></li>
  <li><a href="#present-work-1" id="toc-present-work-1" class="nav-link" data-scroll-target="#present-work-1">Present Work</a>
  <ul class="collapse">
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Advancing Perspectivist Ground Truthing with Social Science</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>AI systems run on data. Data are used to ‘train’ models - imperfect, simplified mathematical or computational representations of a phenomenon or process in the real world <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Where an AI system is a complete application with integrated components e.g.&nbsp;an interface, programmatic logic, and one or more models aimed at performing tasks typically requiring human intelligence, the models themselves are embedded components that take inputs (e.g.&nbsp;media like text, images, audio, or data) and produce outputs (e.g.&nbsp;classifications, predictions or some form of decision). The behavior of models, i.e.&nbsp;how they respond to a given input, is determined by their parameters - internal settings or values. Algorithms - step by step instructions, executed in order - are used to estimate model parameters from the ‘training’ data. As models used in AI systems are designed to perform tasks, their performance is evaluated empirically by comparing their outputs to a reference. This reference is often a second form of data, referred to as the ‘ground truth’, ‘gold standard’, or simply ‘annotations’, which represents the ideal output of the system.</p>
<p>Training data may be tabular data, but is often a form of media - text, audio, images, or video - whereas reference data very often contains aggregated input from humans. This implies that a phenomenon of interest is set as a target, and human judges are given a task that produces data relevant to the target from their input. Commonscenarios include human judges annotating, labeling, or rating a) individual pieces of content of the same form as the training data, or b) generated system outputs. Multiple ratings per piece of content are collected and usually aggregated, forming a singular ‘ground truth’ for the aspect of the content being labelled or rated. Thus, it is assumed that there is a singular canonical truth for each aspect / content pair, comprised of aggregated human responses, which forms a target to which we align our automated systems.</p>
<p>Whether used as part of the development of an AI system, or to evaluate it, the quality of these two forms of data determines the quality of the system. As parameters are estimated from the training data, such that observable patterns recognized in the data affect internal model values or settings, imperfections, inaccuracies, biases etc. in the data are reflected in the parameters of the resulting model. As models are evaluated by comparing their outputs to reference data, such that ‘better’ models are those whose outputs most closely resemble the reference data, imperfections in the reference are reflected in the models preferred. Thus, the quality of the data used for training and reference represents the upper boundary of potential performance of AI systems when deployed: the best possible performance directly corresponds to the degree to which training and reference data represent the phenomenon of interest to the system when deployed.</p>
</section>
<section id="the-data-work-is-design-work" class="level1">
<h1>The Data Work is Design Work</h1>
<p>Although far more emphasis is placed on whether models achieve state of the art ‘performance’ or efficiency <span class="citation" data-cites="birhane2022values">(<a href="#ref-birhane2022values" role="doc-biblioref">Birhane et al., 2022</a>)</span>, scholars over the past decade have attempted to draw attention to a lack of sophistication in how training and reference data are selected and evaluated. It has been argued that a focus on improving the data, will result in bigger gains than a focus on improving the model<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Further, simply collecting a large data set can not compensate for the shortcomings in data set quality <span class="citation" data-cites="hullman2022worst">(<a href="#ref-hullman2022worst" role="doc-biblioref">Hullman et al., 2022</a>)</span>.</p>
<p>Best practices, considerations, and frameworks from the social sciences could inform designs, but have yet to be broadly applied in the computational sciences <span class="citation" data-cites="beck2022improving jacobs2021measurement">(<a href="#ref-beck2022improving" role="doc-biblioref">Beck et al., 2022</a>; <a href="#ref-jacobs2021measurement" role="doc-biblioref">Jacobs &amp; Wallach, 2021</a>)</span>. One reason for this gap may be ML researchers prefer to work on building systems and evaluating their performance rather than researching, designing and executing ground-truthing projects <span class="citation" data-cites="sambasivan2021everyone">(<a href="#ref-sambasivan2021everyone" role="doc-biblioref">Sambasivan et al., 2021</a>)</span>. Another may be a lack of focus on these topics in textbooks, and thus in education more broadly (first geiger paper I think). A third may be that the social and computational sciences have conceptually different focci: the computational sciences focus on the statistical model the system with substantially less emphasis on the content, whereas the social sciences treat the statistical model as a means to better understanding the relationships in the content <span class="citation" data-cites="liem2018psychology">(<a href="#ref-liem2018psychology" role="doc-biblioref">Liem et al., 2018</a>)</span>. Psychology research thus contains many more research projects in which datasets are collected using responses from people, whereas datasets tend to be re-used extensively in machine learning work <span class="citation" data-cites="geiger2021garbage">(<a href="#ref-geiger2021garbage" role="doc-biblioref">Geiger et al., 2021</a>)</span>. A further more practical complication is that work on these topics and potential solutions lacks a central academic ‘home’: where psychology and economics have psychometrics and econometrics respectively, and where software engineering has software testing, the study of ground-truthing lacks a central banner under which academic work can accumulate and disseminate.</p>
<p>Commonly observed shortcomings include 1) representational biases in the content sampled for inclusion in training/evaluation datasets <span class="citation" data-cites="hullman2022worst">(<a href="#ref-hullman2022worst" role="doc-biblioref">Hullman et al., 2022</a>)</span>, 2) measurement biases in the annotations collected <span class="citation" data-cites="jacobs2021measurement hullman2022worst beck2022improving">(<a href="#ref-beck2022improving" role="doc-biblioref">Beck et al., 2022</a>; <a href="#ref-hullman2022worst" role="doc-biblioref">Hullman et al., 2022</a>; <a href="#ref-jacobs2021measurement" role="doc-biblioref">Jacobs &amp; Wallach, 2021</a>)</span>, 3) a fallacious assumption of a single canonical ‘ground-truth’ <span class="citation" data-cites="aroyo2015truth cabitza2023toward">(<a href="#ref-aroyo2015truth" role="doc-biblioref">Aroyo &amp; Welty, 2015</a>; <a href="#ref-cabitza2023toward" role="doc-biblioref">Cabitza et al., 2023</a>)</span>, and 4) poor reporting of necessary information regarding the annotation-collection process <span class="citation" data-cites="hullman2022worst geiger2021garbage">(<a href="#ref-geiger2021garbage" role="doc-biblioref">Geiger et al., 2021</a>; <a href="#ref-hullman2022worst" role="doc-biblioref">Hullman et al., 2022</a>)</span>. An additional consideration that receives little attention is the number of annotations to gather, where fields that focus on gathering data from humans also have a strong emphasis on <em>a-priori</em> decisions to mitigate bias, such as the pre-registration of calculated of target sample sizes. These considerations are absent in computational fields which appear to favor differing rules of thumb: e.g.&nbsp;in a well-cited textbook, <span class="citation" data-cites="PustejovskyStubbsNLannotation">Pustejovsky &amp; Stubbs (<a href="#ref-PustejovskyStubbsNLannotation" role="doc-biblioref">2013</a>)</span> suggest to “have your corpus annotated by at least two people (more is preferable, but not always practical)”, whereas <span class="citation" data-cites="artstein2008inter">Artstein &amp; Poesio (<a href="#ref-artstein2008inter" role="doc-biblioref">2008</a>)</span> suggest that “measuring reliability with only two coders is seldom enough, except for small-scale studies”.</p>
<p>Decisions such as the selection of items for training data <span class="citation" data-cites="hullman2022worst">(<a href="#ref-hullman2022worst" role="doc-biblioref">Hullman et al., 2022</a>)</span>, and the collection of human responses for reference data <span class="citation" data-cites="beck2022improving">(<a href="#ref-beck2022improving" role="doc-biblioref">Beck et al., 2022</a>)</span>, are part of a design of a process that results in data. On the one hand, corpora tend to be very large, and resources are finite. On the other hand, rules of thumb lack clear substantiation in light of the both 1) the phenomenon being grounded and 2) the ambiguity of the media in which it is grounded. In other words, more variance is expected in annotation targets to the degree they are subjective or based on opinion <span class="citation" data-cites="beck2022improving">(<a href="#ref-beck2022improving" role="doc-biblioref">Beck et al., 2022</a>)</span>, and more variance is expected in content to the degree to which it is ambiguous - i.e.&nbsp;can be interpreted in multiple ways - such as figurative language <span class="citation" data-cites="sandri2023don">(<a href="#ref-sandri2023don" role="doc-biblioref">Sandri et al., 2023</a>)</span>. Further some degree of variance will always be present when there are multiple annotations or ratings for a given piece of media independent of the target <span class="citation" data-cites="cabitza">(<a href="#ref-cabitza" role="doc-biblioref"><strong>cabitza?</strong></a>)</span>, based on the range of reasonable interpretations of that target in that media <span class="citation" data-cites="arroyo">(<a href="#ref-arroyo" role="doc-biblioref"><strong>arroyo?</strong></a>)</span>.</p>
<section id="present-work" class="level2">
<h2 class="anchored" data-anchor-id="present-work">Present Work</h2>
<p>Although works have been published that take the aforementioned</p>
<p>This thesis incorporates techniques and considerations from the social sciences to address the aforementioned shortcomings</p>
<p>showcases a design for a challenging ground-truthing project, in terms of the complexity of the phenomenon of interest, ambiguity in the media that selected and annotated. It incorporates design choices to address the aforementioned shortcomings into a singular framework, guided by best practices in the social sciences, which it then extends. It focuses unambiguously on the aspect most relevant to the</p>
<p>Specifically:</p>
<ul>
<li>We attempt to mitigate representation biases in the content we select for annotation by using a stratified sampling strategy.</li>
<li>We attempt to mitigate measurement biases by treating the target measurement as a latent variable, and the survey we used to gather annotations as an instrument. We build on work that validated a questionnaire for measuring constructs, and estimating its reliability and structural validity when used for annotations.</li>
<li>We account for the potential of multiple perspectives in our dataset by recruiting participants from relevant subgroups in a single target population.</li>
<li>We report the details of the annotation collection process, and share the disaggregated dataset of the annotations</li>
<li>We further show how to estimate the number of annotators<br>
</li>
</ul>
<p>We demonstrate the potential of this framework by grounding a complex phenomenon (a 10-dimensional construct, Personal Values) in ambiguous text (song lyrics). We further show an</p>
<p>When sampling content to include in training/test datasets, samples for the training/test sets will ideally be drawn from the same distribution as the content in which they will eventually be deployed. <em>Representation bias</em> in content selected for training and/or evaluation datasets refers to the degree to which relevant distributions in data used to train and/or evaluate systems resembles the distribution in the environment to which it will be deployed <span class="citation" data-cites="hullman2022worst">(<a href="#ref-hullman2022worst" role="doc-biblioref">Hullman et al., 2022</a>)</span>.</p>
<p>Measurement bias in the annotations collected from humans may also bias</p>
<p>Perspectivism</p>
<p>Reporting</p>
<p>We add: a priori rating number estimation</p>
<p>And although imperfect as leaderboard scores can be gamed, and do not perfectly represent the deployment environment, the typical leaderboard approach has shown evidence that progress can be made towards a target. This thesis thus represents an attempt to define the target better.</p>
</section>
</section>
<section id="mlai-relies-on-reference-data-from-human-annotations" class="level1">
<h1>ML/AI relies on reference data from human annotations</h1>
<p><span class="citation" data-cites="aroyo2015truth">Aroyo &amp; Welty (<a href="#ref-aroyo2015truth" role="doc-biblioref">2015</a>)</span></p>
<ul>
<li>In order to evaluate ML / AI systems, we compare the output of these systems to reference data.</li>
<li>One method for creating reference data is the collection of human annotations.</li>
<li>This method typically assumes that, for every piece of content being annotated, there is a single canonical truth</li>
<li>quality of annotations is assessed using inter-annotator agreement, where more agreement = better annotations</li>
</ul>
<p><span class="citation" data-cites="cabitza2023toward">Cabitza et al. (<a href="#ref-cabitza2023toward" role="doc-biblioref">2023</a>)</span>: “data annotation is the practice of labeling a set of digital representations of objects.”</p>
<p>according to Muller et al., 2012 it has three components</p>
<ul>
<li>data collection: the labeling scheme</li>
<li>data annotation: the actual labeling by experts or crowd workers</li>
<li>data aggregation: producing a single or a single set of labels from the multiple labels collected</li>
</ul>
<p><span class="citation" data-cites="geiger2021garbage">Geiger et al. (<a href="#ref-geiger2021garbage" role="doc-biblioref">2021</a>)</span>: ML uses human annotations very often</p>
<ul>
<li>200 randomly sampled ML papers from 3 domains:
<ul>
<li>Social Sciences &amp; Humanities</li>
<li>Life &amp; Biomedical Sciences</li>
<li>Physical &amp; Environmental Sciences</li>
</ul></li>
<li>Out of 141 classification tasks, 103 (73.05%) used human labels</li>
<li>Out of 103 human labels, 58 (56.31%) used only external labels</li>
</ul>
<p>i.e.&nbsp;ML re-uses external labels</p>
<section id="issues-using-human-annotations-in-ml" class="level2">
<h2 class="anchored" data-anchor-id="issues-using-human-annotations-in-ml">Issues using human annotations in ML</h2>
<p>A number of works have shown issues with annotations in ML</p>
<p><span class="citation" data-cites="hullman2022worst">Hullman et al. (<a href="#ref-hullman2022worst" role="doc-biblioref">2022</a>)</span> compare claims that ML is facing a reproducibility crisis to the crisis in psychology. Among the issues they note relate to benchmark datasets, which researchers often re-use as they publish on standardized benchmarks, and because they are cost prohibitive to collect.</p>
<p>Another may be that the skills are not being taught: [geiger, first paper, show lack of reporting in ML textbooks on ground truthing]</p>
<p>A number of papers have drawn from the social sciences to synthesize knowledge on how best to gather annotations.</p>
<section id="ml-treats-all-annotation-variance-as-noise-rather-than-signal" class="level3">
<h3 class="anchored" data-anchor-id="ml-treats-all-annotation-variance-as-noise-rather-than-signal">ML treats all annotation variance as noise rather than signal</h3>
<p>disagreement is common</p>
<p>reviewed in <span class="citation" data-cites="cabitza2023toward">Cabitza et al. (<a href="#ref-cabitza2023toward" role="doc-biblioref">2023</a>)</span>: -social media content: Chandrasekharan 2017 -medical cases: Cabitza 2019 -various NLP tasks <span class="citation" data-cites="aroyo2015truth">Aroyo &amp; Welty (<a href="#ref-aroyo2015truth" role="doc-biblioref">2015</a>)</span></p>
<p>disagreement is often removed</p>
<ul>
<li>adjusting annotator training and instruction</li>
<li>adjusting annotations via discussion post-collection</li>
<li>majority voting, post-hoc without annotators</li>
</ul>
<p>Beyond errors in judgment are questions about the target for the annotations. For at least some phenomena, the assumption that there is a single ground-truth to approximate with annotations doesn’t hold.</p>
<p><span class="citation" data-cites="aroyo2015truth">Aroyo &amp; Welty (<a href="#ref-aroyo2015truth" role="doc-biblioref">2015</a>)</span></p>
<p>7 ‘myths’ of human annotation:</p>
<ul>
<li>there is one truth</li>
<li>disagreement is bad</li>
<li>detailed guidelines help</li>
<li>experts are better</li>
<li>one annotator is enough</li>
<li>all items are created equal</li>
<li>once done, forever valid</li>
</ul>
<p>For myths 1 and 2:</p>
<ul>
<li>list examples from NLP where the disagreement from annotators is sensible</li>
<li>they argue that the assumptions of a single ground truth, and that disagreement is indicative of poor annotations are both false.</li>
</ul>
<p>for myth 6: disagreement indicates that the media being rated is ambiguous.</p>
<section id="annotations-aim-to-measure-a-latent-variable" class="level4">
<h4 class="anchored" data-anchor-id="annotations-aim-to-measure-a-latent-variable">annotations aim to measure a latent variable</h4>
<p><span class="citation" data-cites="jacobs2021measurement">Jacobs &amp; Wallach (<a href="#ref-jacobs2021measurement" role="doc-biblioref">2021</a>)</span> there is a ‘measurement error model’ (taken from econ) that links the unobservable latent variable, and observable properties. in annotations this is via individual observations</p>
<p>although paper focuses on attempts at measuring constructs (risk of recidivism, teacher effectiveness, patient benefit) they also show that even ‘representational measurements’ like height, are essentially a latent variable</p>
<p><span class="citation" data-cites="aroyo2015truth">Aroyo &amp; Welty (<a href="#ref-aroyo2015truth" role="doc-biblioref">2015</a>)</span> operationalize ‘crowd truth’ with an illustration where the ‘gold standard’ is the probability that a sentence contains an element, based on the probability that an annotator annotated that sentence with that element.</p>
<ul>
<li>i.e.&nbsp;the label isn’t represented as ‘present’ or ‘not present’, but as a probablility</li>
<li>thus the ‘crowd truth’ attempts to capture the ‘range of reasonable interpretations’</li>
</ul>
<p><span class="citation" data-cites="beck2022improving">Beck et al. (<a href="#ref-beck2022improving" role="doc-biblioref">2022</a>)</span>: we should expect more variance to the degree that tasks measure opinion show work on an intuitively perspective-based use-case: hate speech</p>
</section>
</section>
<section id="human-annotations-arent-always-accurate" class="level3">
<h3 class="anchored" data-anchor-id="human-annotations-arent-always-accurate">Human annotations aren’t always accurate</h3>
<p><span class="citation" data-cites="griffin2004perspectives">Griffin &amp; Brenner (<a href="#ref-griffin2004perspectives" role="doc-biblioref">2004</a>)</span> review errors and biases in human judgements<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<ul>
<li>over/under prediction: confidence score is higher/lower than accuracy</li>
<li>over/under extremity: confidence is more extreme at ends</li>
</ul>
<p>also reviews possible reasons:</p>
<ul>
<li>optimistic overconfidence</li>
<li>confirmation bias</li>
<li>case-based judgment</li>
<li>ecological probability</li>
<li>error model (psychometric model)</li>
</ul>
</section>
<section id="inadequate-reporting" class="level3">
<h3 class="anchored" data-anchor-id="inadequate-reporting">Inadequate reporting</h3>
<p><span class="citation" data-cites="geiger2021garbage">Geiger et al. (<a href="#ref-geiger2021garbage" role="doc-biblioref">2021</a>)</span> ML science studies inadequately report ‘ground truth’</p>
<p><span class="citation" data-cites="hullman2022worst">Hullman et al. (<a href="#ref-hullman2022worst" role="doc-biblioref">2022</a>)</span> thus we cannot know what data generating process the resulting model represents</p>
<p>[perhaps cat image parable here?]</p>
</section>
<section id="sampling-and-measurement-biases" class="level3">
<h3 class="anchored" data-anchor-id="sampling-and-measurement-biases">sampling and measurement biases</h3>
<p><span class="citation" data-cites="hullman2022worst">Hullman et al. (<a href="#ref-hullman2022worst" role="doc-biblioref">2022</a>)</span></p>
<p>With regards to reference data:</p>
<ul>
<li>representation bias / non-representative samples</li>
<li>measurement bias / unvalidated measurement instruments</li>
<li>underspecification of portions of input space in training data</li>
<li>transformation of data to optimize for ‘accuracy’</li>
<li>lack of or poor dataset documentation</li>
</ul>
<p>In other words, optimizing for predictive accuracy using very large datasets does not ‘absolve’ researchers from having to consider the data generating process. They note benefits that both machine learning and psychology could gain by borrowing methods from each other, but note the danger if these are misused. For the benefit of machine learning, there are lessons to be learned from social science, and the replication crisis. Among them are 1) collecting samples whose test/evaluation set distributions are drawn from the same deployment distribution, and 2) using valid measurement instruments.</p>
</section>
<section id="ml-doesnt-treat-annotation-generating-process-as-an-instrument" class="level3">
<h3 class="anchored" data-anchor-id="ml-doesnt-treat-annotation-generating-process-as-an-instrument">ML doesn’t treat annotation generating process as an instrument</h3>
<p><span class="citation" data-cites="beck2022improving">Beck et al. (<a href="#ref-beck2022improving" role="doc-biblioref">2022</a>)</span></p>
<ul>
<li>annotation collection requires design thinking
<ul>
<li>Task Structure: specific wording and response options, including debates over the inclusion of “I don’t Know” option</li>
<li>Order Effects: specific judgements are affected by previous perceptions</li>
<li>Annotator Effects: backgrounds, opinions, experiences of respondents affect responses</li>
</ul></li>
</ul>
<p><span class="citation" data-cites="jacobs2021measurement">Jacobs &amp; Wallach (<a href="#ref-jacobs2021measurement" role="doc-biblioref">2021</a>)</span></p>
<ul>
<li>reliability: do similar inputs to a measurement model present similar outputs?</li>
</ul>
<p>test-retest: are measurements of an unobservable latent construct taken at different times via a measurement model similar, assuming the construct hasn’t changed?</p>
<ul>
<li>validity: is it ‘right’?</li>
</ul>
<p>no single test for validity on purpose, because it requires thinking. do our measurements:</p>
<ul>
<li>face validity: look plausible/ sensible?</li>
<li>content validity: capture the construct?
<ul>
<li>structural validity: show the inter-correlations we expect?</li>
<li>substantive validity: capture only observable properties thought to be related to the construct?</li>
</ul></li>
<li>convergent validity: show correlations with other validated methods?</li>
<li>discriminant validity: show correlations with other construct/properties thought not to be related to the construct?</li>
<li>predictive validity: show correlations with constructs/properties thought to be related, but not in the operationalization?</li>
<li>hypothesis validity: shed light on relevant hypotheses about the construct being measured?</li>
<li>consequential validity: allow for the consequences obtained from the measurement model to be assessed?</li>
</ul>
</section>
<section id="ml-ignores-perspectives-of-annotators" class="level3">
<h3 class="anchored" data-anchor-id="ml-ignores-perspectives-of-annotators">ML ignores perspectives of annotators</h3>
<p><span class="citation" data-cites="cabitza2023toward">Cabitza et al. (<a href="#ref-cabitza2023toward" role="doc-biblioref">2023</a>)</span>: whether the target of the annotation is a subjective phenomenon or not, disagreement is always irreducible. Yet ML typically assumes there is a single ‘ground truth’, and its best indicator is inter-annotator agreement. But taking the perspectives of the annotators into account, both in the data annotation but also the modelling phase of ML projects has recently been shown to benefit ML modelling in a number of contexts.</p>
<p>weak perspectivist approach: taking perspectives into account while designing and collecting annotations, but ultimately reducing annotations to a single label or rating.</p>
<p>strong perspectivist approach: taking perspectives into account for ground truthing and modelling phases.</p>
<p>benefits of this approach:</p>
<ul>
<li><p>is congruent with the reality of collecting annotations</p></li>
<li><p>includes the signal in the variance of labels or ratings</p></li>
<li><p>avoids majority group perspective appearing to be ‘objective’</p></li>
<li><p>allows for the modelling of human errors and variances</p></li>
<li><p>allows for uncertain, fuzzy, or soft model development</p></li>
<li><p>more complete report of the data generating process, as it also reports uncertainty</p></li>
</ul>
<p>downsides:</p>
<ul>
<li><p>multiple raters, and therefore costs/time/rater availability are issues</p></li>
<li><p>need for perspectivist ML approaches</p></li>
<li><p>validation becomes more challenging</p></li>
</ul>
<p>recommendations:</p>
<ul>
<li><p>complete labeling schemes, including ‘i don’t know’, ‘none of these’ etc. categories, and the ability to express issues with label set</p></li>
<li><p>enough raters</p></li>
<li><p>heterogenous raters</p></li>
<li><p>adequate reporting:</p>
<ul>
<li><p>number of raters,</p></li>
<li><p>rater expertise</p></li>
<li><p>incentive</p></li>
<li><p>instructions</p></li>
<li><p>length of time for labelling</p></li>
<li><p>inter rater agreement</p></li>
<li><p>aggregation method</p></li>
<li><p>confidence</p></li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="tools-from-social-science-can-help" class="level1">
<h1>Tools from Social Science can help</h1>
<p>Recent trends—especially in deep learning—prioritize empirical performance over theoretical assumptions about the data generating process. A systematic analysis of highly cited ML works shows that Performance, Generalization, Quantitative evidence, Efficiency, Building on past work, and Novelty are the primary values in ML work <span class="citation" data-cites="birhane2022values">Birhane et al. (<a href="#ref-birhane2022values" role="doc-biblioref">2022</a>)</span>.</p>
<p>Unlike the social sciences (e.g.&nbsp;psychology), ML work ignores attempts to model the process that gives rise to the data, assuming it cannot be learned, and aims instead at predictors that will within estimable error bounds <span class="citation" data-cites="hullman2022worst">Hullman et al. (<a href="#ref-hullman2022worst" role="doc-biblioref">2022</a>)</span>. This is problematic as this kind of optimization doesn’t resemble real world deployment.</p>
<section id="social-and-computational-sciences-have-different-focci" class="level3">
<h3 class="anchored" data-anchor-id="social-and-computational-sciences-have-different-focci">Social and computational sciences have different focci</h3>
<p>social sciences:</p>
<ul>
<li>interpretable meaning of x and y</li>
<li>design is informed by theory</li>
</ul>
<p>computational sciences:</p>
<ul>
<li>learning procedure f(x)</li>
</ul>
<p><img src="images/Liem_2018_figure_1.png" class="img-fluid"> Fig. 1: <span class="citation" data-cites="liem2018psychology">Liem et al. (<a href="#ref-liem2018psychology" role="doc-biblioref">2018</a>)</span></p>
</section>
<section id="issues-with-sampling" class="level3">
<h3 class="anchored" data-anchor-id="issues-with-sampling">Issues with sampling</h3>
<p>Solutions to sampling problems can come from sampling theory: <span class="citation" data-cites="groves2009survey">Groves et al. (<a href="#ref-groves2009survey" role="doc-biblioref">2009</a>)</span></p>
<p>considerations:</p>
<ul>
<li>sampling frame: the elements in from populations that you have access to</li>
<li>ineligible units: elements in the sampling frame that are not your target</li>
<li>undercoverage: elements from target population that are not in the frame</li>
</ul>
<p>solutions:</p>
<ul>
<li>stratified sampling</li>
</ul>
</section>
<section id="issues-with-instruments" class="level3">
<h3 class="anchored" data-anchor-id="issues-with-instruments">Issues with instruments</h3>
<p><span class="citation" data-cites="beck2022improving">Beck et al. (<a href="#ref-beck2022improving" role="doc-biblioref">2022</a>)</span></p>
<ul>
<li>annotation collection requires design thinking
<ul>
<li>Task Structure: specific wording and response options, including debates over the inclusion of “I don’t Know” option</li>
<li>Order Effects: specific judgements are affected by previous perceptions</li>
<li>Annotator Effects: backgrounds, opinions, experiences of respondents affect responses</li>
</ul></li>
</ul>
<p>[another ref that describes the target as a latent variable]</p>
</section>
<section id="a-tale-of-two-studies-the-case-of-personnel-selection" class="level3">
<h3 class="anchored" data-anchor-id="a-tale-of-two-studies-the-case-of-personnel-selection">A tale of two studies: the case of personnel selection</h3>
<p><span class="citation" data-cites="ponce2016chalearn">Ponce-López et al. (<a href="#ref-ponce2016chalearn" role="doc-biblioref">2016</a>)</span></p>
<ul>
<li>efficient way to gather media and annotation data</li>
<li>BUT no validation of instrument, or ecologically valid media data</li>
<li>distribution of training /eval data don’t come from the target distribution</li>
</ul>
<p><img src="images/Ponce_Lopez_2016_figure_2.png" class="img-fluid"> Figure 2: <span class="citation" data-cites="ponce2016chalearn">Ponce-López et al. (<a href="#ref-ponce2016chalearn" role="doc-biblioref">2016</a>)</span></p>
<p>Compared to <span class="citation" data-cites="koutsoumpis2024beyond">Koutsoumpis et al. (<a href="#ref-koutsoumpis2024beyond" role="doc-biblioref">2024</a>)</span>:</p>
<ul>
<li>ecological validity: media data was mock asynchronous video interviews</li>
<li>ecological validity: interview questions designed to activate personality facets</li>
<li>personality instruments: validated HEXACO scale</li>
<li>perspectives: self &amp; observer ratings</li>
</ul>
</section>
</section>
<section id="present-work-1" class="level1">
<h1>Present Work</h1>
<p>We incorporate these considerations in the design of our study, and attempt to further the field in the following ways:</p>
<ul>
<li>we attempt representative sampling of both media and respondents</li>
<li>we aim to estimate 10-dimensional psychological construct</li>
<li>we select media that is ambiguous (i.e.&nbsp;that will result in subjectivity in the ratings) as well as media that we expect not to be ambiguous for comparison</li>
<li>we estimate a-priori the number of ratings necessary rather than assuming</li>
<li>we take into account perspectives</li>
</ul>
<p>case study of this thesis works towards path (b) in <span class="citation" data-cites="liem2018psychology">Liem et al. (<a href="#ref-liem2018psychology" role="doc-biblioref">2018</a>)</span> shown in: <img src="images/Liem_2018_figure_2.png" class="img-fluid"></p>
<section id="references" class="level2">




</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-aroyo2015truth" class="csl-entry" role="listitem">
Aroyo, L., &amp; Welty, C. (2015). Truth is a lie: Crowd truth and the seven myths of human annotation. <em>AI Magazine</em>, <em>36</em>(1), 15–24.
</div>
<div id="ref-artstein2008inter" class="csl-entry" role="listitem">
Artstein, R., &amp; Poesio, M. (2008). Inter-coder agreement for computational linguistics. <em>Computational Linguistics</em>, <em>34</em>(4), 555–596.
</div>
<div id="ref-beck2022improving" class="csl-entry" role="listitem">
Beck, J., Eckman, S., Chew, R., &amp; Kreuter, F. (2022). Improving labeling through social science insights: Results and research agenda. <em>International Conference on Human-Computer Interaction</em>, 245–261.
</div>
<div id="ref-birhane2022values" class="csl-entry" role="listitem">
Birhane, A., Kalluri, P., Card, D., Agnew, W., Dotan, R., &amp; Bao, M. (2022). The values encoded in machine learning research. <em>Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</em>, 173–184.
</div>
<div id="ref-cabitza2023toward" class="csl-entry" role="listitem">
Cabitza, F., Campagner, A., &amp; Basile, V. (2023). Toward a perspectivist turn in ground truthing for predictive computing. <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, <em>37</em>, 6860–6868.
</div>
<div id="ref-geiger2021garbage" class="csl-entry" role="listitem">
Geiger, R. S., Cope, D., Ip, J., Lotosh, M., Shah, A., Weng, J., &amp; Tang, R. (2021). " garbage in, garbage out" revisited: What do machine learning application papers report about human-labeled training data? <em>arXiv Preprint arXiv:2107.02278</em>.
</div>
<div id="ref-griffin2004perspectives" class="csl-entry" role="listitem">
Griffin, D., &amp; Brenner, L. (2004). Perspectives on probability judgment calibration. <em>Blackwell Handbook of Judgment and Decision Making</em>, <em>199</em>, 158–177.
</div>
<div id="ref-groves2009survey" class="csl-entry" role="listitem">
Groves, R. M., Fowler Jr, F. J., Couper, M. P., Lepkowski, J. M., Singer, E., &amp; Tourangeau, R. (2009). <em>Survey methodology</em> (Vol. 561). John Wiley &amp; Sons.
</div>
<div id="ref-hullman2022worst" class="csl-entry" role="listitem">
Hullman, J., Kapoor, S., Nanayakkara, P., Gelman, A., &amp; Narayanan, A. (2022). The worst of both worlds: A comparative analysis of errors in learning from data in psychology and machine learning. <em>Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society</em>, 335–348.
</div>
<div id="ref-jacobs2021measurement" class="csl-entry" role="listitem">
Jacobs, A. Z., &amp; Wallach, H. (2021). Measurement and fairness. <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 375–385.
</div>
<div id="ref-koutsoumpis2024beyond" class="csl-entry" role="listitem">
Koutsoumpis, A., Ghassemi, S., Oostrom, J. K., Holtrop, D., Breda, W. van, Zhang, T., &amp; Vries, R. E. de. (2024). Beyond traditional interviews: Psychometric analysis of asynchronous video interviews for personality and interview performance evaluation using machine learning. <em>Computers in Human Behavior</em>, <em>154</em>, 108128.
</div>
<div id="ref-liem2018psychology" class="csl-entry" role="listitem">
Liem, C. C., Langer, M., Demetriou, A., Hiemstra, A. M., Sukma Wicaksana, A., Born, M. P., &amp; König, C. J. (2018). Psychology meets machine learning: Interdisciplinary perspectives on algorithmic job candidate screening. <em>Explainable and Interpretable Models in Computer Vision and Machine Learning</em>, 197–253.
</div>
<div id="ref-ponce2016chalearn" class="csl-entry" role="listitem">
Ponce-López, V., Chen, B., Oliu, M., Corneanu, C., Clapés, A., Guyon, I., Baró, X., Escalante, H. J., &amp; Escalera, S. (2016). Chalearn lap 2016: First round challenge on first impressions-dataset and results. <em>Computer Vision–ECCV 2016 Workshops: Amsterdam, the Netherlands, October 8-10 and 15-16, 2016, Proceedings, Part III 14</em>, 400–418.
</div>
<div id="ref-PustejovskyStubbsNLannotation" class="csl-entry" role="listitem">
Pustejovsky, J., &amp; Stubbs, A. (2013). <em><span class="nocase">Natural language annotation for machine learning </span></em> (First Edition). O’Reilly Media.
</div>
<div id="ref-sambasivan2021everyone" class="csl-entry" role="listitem">
Sambasivan, N., Kapania, S., Highfill, H., Akrong, D., Paritosh, P., &amp; Aroyo, L. M. (2021). <span>“Everyone wants to do the model work, not the data work”</span>: Data cascades in high-stakes AI. <em>Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</em>, 1–15.
</div>
<div id="ref-sandri2023don" class="csl-entry" role="listitem">
Sandri, M., Leonardelli, E., Tonelli, S., &amp; Ježek, E. (2023). Why don’t you do it right? Analysing annotators’ disagreement in subjective tasks. <em>Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</em>, 2428–2441.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>https://en.wikipedia.org/wiki/Scientific_modelling<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>https://www.youtube.com/watch?v=06-AZXmwHjo<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><span class="citation" data-cites="griffin2004perspectives">Griffin &amp; Brenner (<a href="#ref-griffin2004perspectives" role="doc-biblioref">2004</a>)</span> note that much of this work was about people guessing knowledge from an almanac, and then guessing how accurate they were<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>